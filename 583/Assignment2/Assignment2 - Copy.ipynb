{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvZ2JCnFwBaj"
      },
      "source": [
        "# Assignment 2: Build a CNN for image recognition.\n",
        "\n",
        "## Due Date:  March 31, 11:59PM\n",
        "\n",
        "### Name: Krystal Hong\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2jdbBq8wBam"
      },
      "source": [
        "## Introduction:\n",
        "\n",
        "1. In this assignment, you will build Convolutional Neural Network to classify CIFAR-10 Images.\n",
        "2. You can directly load dataset from many deep learning packages.\n",
        "3. You can use any deep learning packages such as pytorch, keras or tensorflow for this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyzKOQK8wBan"
      },
      "source": [
        "## Requirements:\n",
        "\n",
        "1. You need to load cifar 10 data and split the entire training dataset into training and validation.\n",
        "2. You will implement a CNN model to classify cifar 10 images with provided structure.\n",
        "3. You need to plot the training and validation accuracy or loss obtained from above step.\n",
        "4. Then you can use tuned hyper-parameters to train using the entire training dataset.\n",
        "5. You should report the testing accuracy using the model with complete data.\n",
        "6. You may try to change the structure (e.g, add BN layer or dropout layer,...) and analyze your findings.\n",
        "\n",
        "## Google Colab\n",
        "\n",
        "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBeA62EdwBan"
      },
      "source": [
        "## Batch Normalization (BN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWUEnaK7wBao"
      },
      "source": [
        "### Background:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLXNQ4kpwBao"
      },
      "source": [
        "- Batch Normalization is a technique to speed up training and help make the model more stable.\n",
        "- In simple words, batch normalization is just another network layer that gets inserted between a hidden layer and the next hidden layer. Its job is to take the outputs from the first hidden layer and normalize them before passing them on as the input of the next hidden layer.\n",
        "\n",
        "- For more detailed information, you may refer to the original paper: https://arxiv.org/pdf/1502.03167.pdf."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUX-lBwOwBao"
      },
      "source": [
        "### BN Algorithm:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcgRavlSwBap"
      },
      "source": [
        "- Input: Values of $x$ over a mini-batch: $\\mathbf{B}$ = $\\{x_1,..., x_m\\};$\n",
        "- Output: $\\{y_i = BN_{\\gamma,\\beta}(x_i)\\}$, $\\gamma, \\beta$ are learnable parameters\n",
        "\n",
        "Normalization of the Input:\n",
        "$$\\mu_{\\mathbf{B}} = \\frac{1}{m}\\sum_{i=1}^m x_i$$\n",
        "$$\\sigma_{\\mathbf{B}}^2 = \\frac{1}{m}\\sum_{i=1}^m (x_i - \\mu_{\\mathbf{B}})^2$$\n",
        "$$\\hat{x_i} = \\frac{x_i - \\mu_{\\mathbf{B}}}{\\sqrt{\\sigma_{\\mathbf{B}}}^2 + \\epsilon}$$\n",
        "Re-scaling and Offsetting:\n",
        "$$y_i = \\gamma \\hat{x_i} + \\beta = BN_{\\gamma,\\beta}(x_i)$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKSsxAjRwBap"
      },
      "source": [
        "### Advantages of BN:\n",
        "1. Improves gradient flow through the network.\n",
        "2. Allows use of saturating nonlinearities and higher learning rates.\n",
        "3. Makes weights easier to initialize.\n",
        "4. Act as a form of regularization and may reduce the need for dropout."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ5Q2x-0wBaq"
      },
      "source": [
        "### Implementation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVwCG3omwBaq"
      },
      "source": [
        "- The batch normalization layer has already been implemented in many packages. You may simply call the function to build the layer. For example: torch.nn.BatchNorm2d() using pytroch package, keras.layers.BatchNormalization() using keras package.\n",
        "- The location of BN layer: Please make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEBTdwnPwBaq"
      },
      "source": [
        "## 1. Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGsp-3e0wBaq"
      },
      "source": [
        "### 1.1. Load data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhX6lC5vwBar",
        "outputId": "be5be75d-73d9-415a-e177-bcc4aad0ea7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of x_train: (50000, 32, 32, 3)\n",
            "shape of y_train: (50000, 1)\n",
            "shape of x_test: (10000, 32, 32, 3)\n",
            "shape of y_test: (10000, 1)\n",
            "number of classes: 10\n"
          ]
        }
      ],
      "source": [
        "# Load Cifar-10 Data\n",
        "# This is just an example, you may load dataset from other packages.\n",
        "import keras\n",
        "import numpy as np\n",
        "import tensorflow.keras\n",
        "### If you can not load keras dataset, un-comment these two lines.\n",
        "#import ssl\n",
        "#ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "print('shape of x_train: ' + str(x_train.shape))\n",
        "print('shape of y_train: ' + str(y_train.shape))\n",
        "print('shape of x_test: ' + str(x_test.shape))\n",
        "print('shape of y_test: ' + str(y_test.shape))\n",
        "print('number of classes: ' + str(np.max(y_train) - np.min(y_train) + 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SSvN7qowBas"
      },
      "source": [
        "### 1.2. One-hot encode the labels (5 points)\n",
        "\n",
        "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
        "\n",
        "1. Implement a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
        "\n",
        "2. Apply the function to ```y_train``` and ```y_test```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhEjfIQBwBas",
        "outputId": "48d0df0c-4ead-40a8-c2c4-6b5c2a5f1c11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of y_train_vec: (50000, 10)\n",
            "Shape of y_test_vec: (10000, 10)\n",
            "[6]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "def to_one_hot(y, num_class=10):\n",
        "    new_y = []\n",
        "    for i in y:\n",
        "        vec = np.zeros(num_class)\n",
        "        vec[i] = 1\n",
        "        new_y.append(vec)\n",
        "    return np.asarray(new_y)\n",
        "\n",
        "y_train_vec = to_one_hot(y_train)\n",
        "y_test_vec = to_one_hot(y_test)\n",
        "\n",
        "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
        "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
        "\n",
        "print(y_train[0])\n",
        "print(y_train_vec[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hb22065IwBas"
      },
      "source": [
        "#### Remark: the outputs should be\n",
        "* Shape of y_train_vec: (50000, 10)\n",
        "* Shape of y_test_vec: (10000, 10)\n",
        "* [6]\n",
        "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-kWxjATwBat"
      },
      "source": [
        "### 1.3. Randomly partition the training set to training and validation sets (5 points)\n",
        "\n",
        "Randomly partition the 50K training samples to 2 sets: \n",
        "* a training set containing 40K samples: x_tr, y_tr\n",
        "* a validation set containing 10K samples: x_val, y_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_wfdOifwBat",
        "outputId": "81487591-44ca-4c60-951e-87987814c890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_tr: (40000, 32, 32, 3)\n",
            "Shape of y_tr: (40000, 10)\n",
            "Shape of x_val: (10000, 32, 32, 3)\n",
            "Shape of y_val: (10000, 10)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(x_train,y_train_vec,test_size=0.2)\n",
        "\n",
        "print('Shape of x_tr: ' + str(x_tr.shape))\n",
        "print('Shape of y_tr: ' + str(y_tr.shape))\n",
        "print('Shape of x_val: ' + str(x_val.shape))\n",
        "print('Shape of y_val: ' + str(y_val.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2hNtt4uwBat"
      },
      "source": [
        "## 2. Build a CNN and tune its hyper-parameters (50 points)\n",
        "\n",
        "- Build a convolutional neural network model using the below structure:\n",
        "\n",
        "- It should have a structure of: Conv - ReLU - Max Pool - ConV - ReLU - Max Pool - Dense - ReLU - Dense - Softmax\n",
        "\n",
        "- In the graph 3@32x32 means the dimension of input image, 32@30x30 means it has 32 filters and the dimension now becomes 30x30 after the convolution.\n",
        "- All convolutional layers (Conv) should have stride = 1 and no padding.\n",
        "- Max Pooling has a pool size of 2 by 2.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVz7qpnSwBat"
      },
      "source": [
        "<img src=\"network.PNG\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYXZ3oZiwBat"
      },
      "source": [
        "- You may use the validation data to tune the hyper-parameters (e.g., learning rate, and optimization algorithm)\n",
        "- Do NOT use test data for hyper-parameter tuning!!!\n",
        "- Try to achieve a validation accuracy as high as possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLpB_GbmwBau",
        "outputId": "f0c2ff2e-a6e3-40e3-cec3-d813871a5b62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_14 (Conv2D)          (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 15, 15, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 12, 12, 64)        32832     \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 6, 6, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 256)               590080    \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 626,378\n",
            "Trainable params: 626,378\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build the model\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "#1 conv, relu, max pool\n",
        "model.add(Conv2D(32, (3, 3), activation = 'relu', input_shape=(32, 32, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "#2 conv, relu, max pool\n",
        "model.add(Conv2D(64, (4, 4), activation = 'relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "#Dense layers\n",
        "model.add(Dense(256, activation = 'relu'))\n",
        "model.add(Dense(10, activation = 'softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "MFmO9yMUwBau"
      },
      "outputs": [],
      "source": [
        "# Define model optimizer and loss function\n",
        "from tensorflow.keras import optimizers\n",
        "model.compile(optimizer=optimizers.RMSprop(learning_rate=0.0001), loss = 'categorical_crossentropy', metrics=['acc'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnXp3qROwBau",
        "outputId": "d5aadfa8-0a84-4c98-b6d9-eaaea3bd2c13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "400/400 [==============================] - 3s 6ms/step - loss: 3.7334 - acc: 0.3064 - val_loss: 1.7417 - val_acc: 0.4055\n",
            "Epoch 2/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 1.5154 - acc: 0.4736 - val_loss: 1.4482 - val_acc: 0.4950\n",
            "Epoch 3/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 1.2760 - acc: 0.5577 - val_loss: 1.3819 - val_acc: 0.5254\n",
            "Epoch 4/50\n",
            "400/400 [==============================] - 2s 6ms/step - loss: 1.1137 - acc: 0.6150 - val_loss: 1.3419 - val_acc: 0.5504\n",
            "Epoch 5/50\n",
            "400/400 [==============================] - 2s 6ms/step - loss: 0.9793 - acc: 0.6610 - val_loss: 1.2842 - val_acc: 0.5703\n",
            "Epoch 6/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.8679 - acc: 0.7026 - val_loss: 1.2650 - val_acc: 0.5813\n",
            "Epoch 7/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.7694 - acc: 0.7369 - val_loss: 1.2917 - val_acc: 0.5796\n",
            "Epoch 8/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.6789 - acc: 0.7710 - val_loss: 1.3055 - val_acc: 0.5873\n",
            "Epoch 9/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.5991 - acc: 0.7991 - val_loss: 1.3131 - val_acc: 0.5968\n",
            "Epoch 10/50\n",
            "400/400 [==============================] - 3s 7ms/step - loss: 0.5200 - acc: 0.8270 - val_loss: 1.3023 - val_acc: 0.6053\n",
            "Epoch 11/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.4546 - acc: 0.8518 - val_loss: 1.3355 - val_acc: 0.6082\n",
            "Epoch 12/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.3906 - acc: 0.8747 - val_loss: 1.4136 - val_acc: 0.6036\n",
            "Epoch 13/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.3350 - acc: 0.8931 - val_loss: 1.4875 - val_acc: 0.6047\n",
            "Epoch 14/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.2868 - acc: 0.9107 - val_loss: 1.4889 - val_acc: 0.6137\n",
            "Epoch 15/50\n",
            "400/400 [==============================] - 2s 6ms/step - loss: 0.2393 - acc: 0.9269 - val_loss: 1.6078 - val_acc: 0.6027\n",
            "Epoch 16/50\n",
            "400/400 [==============================] - 3s 8ms/step - loss: 0.1999 - acc: 0.9419 - val_loss: 1.5888 - val_acc: 0.6211\n",
            "Epoch 17/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.1654 - acc: 0.9532 - val_loss: 1.7014 - val_acc: 0.6073\n",
            "Epoch 18/50\n",
            "400/400 [==============================] - 3s 7ms/step - loss: 0.1374 - acc: 0.9632 - val_loss: 1.7212 - val_acc: 0.6164\n",
            "Epoch 19/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.1121 - acc: 0.9718 - val_loss: 1.7841 - val_acc: 0.6217\n",
            "Epoch 20/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.0911 - acc: 0.9778 - val_loss: 2.0198 - val_acc: 0.6059\n",
            "Epoch 21/50\n",
            "400/400 [==============================] - 3s 7ms/step - loss: 0.0757 - acc: 0.9826 - val_loss: 1.9834 - val_acc: 0.6206\n",
            "Epoch 22/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.0615 - acc: 0.9864 - val_loss: 2.0682 - val_acc: 0.6216\n",
            "Epoch 23/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.0507 - acc: 0.9900 - val_loss: 2.2498 - val_acc: 0.6038\n",
            "Epoch 24/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.0416 - acc: 0.9913 - val_loss: 2.1659 - val_acc: 0.6219\n",
            "Epoch 25/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.0359 - acc: 0.9924 - val_loss: 2.2561 - val_acc: 0.6161\n",
            "Epoch 26/50\n",
            "400/400 [==============================] - 2s 6ms/step - loss: 0.0319 - acc: 0.9930 - val_loss: 2.3502 - val_acc: 0.6216\n",
            "Epoch 27/50\n",
            "400/400 [==============================] - 2s 6ms/step - loss: 0.0263 - acc: 0.9947 - val_loss: 2.3526 - val_acc: 0.6229\n",
            "Epoch 28/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.0247 - acc: 0.9947 - val_loss: 2.4544 - val_acc: 0.6162\n",
            "Epoch 29/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.0218 - acc: 0.9951 - val_loss: 2.4821 - val_acc: 0.6272\n",
            "Epoch 30/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.0175 - acc: 0.9963 - val_loss: 2.7826 - val_acc: 0.6075\n",
            "Epoch 31/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.0185 - acc: 0.9957 - val_loss: 2.5734 - val_acc: 0.6224\n",
            "Epoch 32/50\n",
            "400/400 [==============================] - 3s 7ms/step - loss: 0.0147 - acc: 0.9967 - val_loss: 2.6958 - val_acc: 0.6230\n",
            "Epoch 33/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.0138 - acc: 0.9970 - val_loss: 2.8009 - val_acc: 0.6164\n",
            "Epoch 34/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.0125 - acc: 0.9972 - val_loss: 2.8414 - val_acc: 0.6240\n",
            "Epoch 35/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.0119 - acc: 0.9971 - val_loss: 3.0404 - val_acc: 0.6156\n",
            "Epoch 36/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.0112 - acc: 0.9971 - val_loss: 2.8967 - val_acc: 0.6249\n",
            "Epoch 37/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.0111 - acc: 0.9969 - val_loss: 2.9789 - val_acc: 0.6105\n",
            "Epoch 38/50\n",
            "400/400 [==============================] - 3s 8ms/step - loss: 0.0125 - acc: 0.9969 - val_loss: 2.9104 - val_acc: 0.6169\n",
            "Epoch 39/50\n",
            "400/400 [==============================] - 2s 6ms/step - loss: 0.0117 - acc: 0.9971 - val_loss: 3.0392 - val_acc: 0.6267\n",
            "Epoch 40/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.0098 - acc: 0.9974 - val_loss: 3.0155 - val_acc: 0.6215\n",
            "Epoch 41/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.0105 - acc: 0.9972 - val_loss: 3.0822 - val_acc: 0.6284\n",
            "Epoch 42/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.0087 - acc: 0.9980 - val_loss: 3.0762 - val_acc: 0.6282\n",
            "Epoch 43/50\n",
            "400/400 [==============================] - 2s 6ms/step - loss: 0.0075 - acc: 0.9980 - val_loss: 3.0864 - val_acc: 0.6295\n",
            "Epoch 44/50\n",
            "400/400 [==============================] - 3s 7ms/step - loss: 0.0078 - acc: 0.9980 - val_loss: 3.1716 - val_acc: 0.6262\n",
            "Epoch 45/50\n",
            "400/400 [==============================] - 2s 6ms/step - loss: 0.0066 - acc: 0.9984 - val_loss: 3.2321 - val_acc: 0.6261\n",
            "Epoch 46/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.0067 - acc: 0.9983 - val_loss: 3.3179 - val_acc: 0.6208\n",
            "Epoch 47/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.0077 - acc: 0.9980 - val_loss: 3.1788 - val_acc: 0.6233\n",
            "Epoch 48/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.0065 - acc: 0.9981 - val_loss: 3.4034 - val_acc: 0.6280\n",
            "Epoch 49/50\n",
            "400/400 [==============================] - 3s 7ms/step - loss: 0.0071 - acc: 0.9982 - val_loss: 3.3874 - val_acc: 0.6252\n",
            "Epoch 50/50\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.0061 - acc: 0.9985 - val_loss: 3.4438 - val_acc: 0.6298\n"
          ]
        }
      ],
      "source": [
        "# Train the model and store model parameters/loss values\n",
        "history = model.fit(x_tr, y_tr, batch_size=100, epochs=50, validation_data=(x_val, y_val))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSDyJozpwBau"
      },
      "source": [
        "## 3. Plot the training and validation loss curve versus epochs. (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "IC9-mrKDwBav",
        "outputId": "fe42141a-16de-49da-f7f3-f9a7896e00e7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plot the loss curve\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "epochs = range(50)\n",
        "train_acc = history.history['acc']\n",
        "valid_acc = history.history['val_acc']\n",
        "plt.plot(epochs, train_acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, valid_acc, 'r', label='Validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IAOLi42wBav"
      },
      "source": [
        "## 4. Train (again) and evaluate the model (5 points)\n",
        "\n",
        "- To this end, you have found the \"best\" hyper-parameters. \n",
        "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
        "- Evaluate your model on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9iOTxhiwBav"
      },
      "source": [
        "### Train the model on the entire training set\n",
        "\n",
        "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "foSksC1TwBav"
      },
      "outputs": [],
      "source": [
        "#<Compile your model again (using the same hyper-parameters you tuned above)>\n",
        "\n",
        "model2 = models.Sequential()\n",
        "#1 conv, relu, max pool\n",
        "model2.add(Conv2D(32, (3, 3), activation = 'relu', input_shape=(32, 32, 3)))\n",
        "model2.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "#2 conv, relu, max pool\n",
        "model2.add(Conv2D(64, (4, 4), activation = 'relu'))\n",
        "model2.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model2.add(Flatten())\n",
        "#Dense layers\n",
        "model2.add(Dense(256, activation = 'relu'))\n",
        "model2.add(Dense(10, activation = 'softmax'))\n",
        "\n",
        "#Optimizer\n",
        "model2.compile(optimizer=optimizers.RMSprop(learning_rate=0.0001), loss = 'categorical_crossentropy', metrics=['acc'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVHCY_WiwBav",
        "outputId": "68ec65c8-be9e-4f44-92b4-41e3a4b88e57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "500/500 [==============================] - 4s 5ms/step - loss: 3.6264 - acc: 0.3047 - val_loss: 1.5392 - val_acc: 0.4524\n",
            "Epoch 2/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 1.4360 - acc: 0.4948 - val_loss: 1.3603 - val_acc: 0.5308\n",
            "Epoch 3/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 1.2069 - acc: 0.5819 - val_loss: 1.0443 - val_acc: 0.6354\n",
            "Epoch 4/50\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 1.0567 - acc: 0.6352 - val_loss: 0.9168 - val_acc: 0.6873\n",
            "Epoch 5/50\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.9350 - acc: 0.6782 - val_loss: 0.7992 - val_acc: 0.7331\n",
            "Epoch 6/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.8265 - acc: 0.7176 - val_loss: 0.7469 - val_acc: 0.7486\n",
            "Epoch 7/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.7320 - acc: 0.7490 - val_loss: 0.6669 - val_acc: 0.7748\n",
            "Epoch 8/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.6471 - acc: 0.7809 - val_loss: 0.5561 - val_acc: 0.8125\n",
            "Epoch 9/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.5705 - acc: 0.8068 - val_loss: 0.4620 - val_acc: 0.8538\n",
            "Epoch 10/50\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.5001 - acc: 0.8345 - val_loss: 0.4011 - val_acc: 0.8759\n",
            "Epoch 11/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.4371 - acc: 0.8572 - val_loss: 0.3577 - val_acc: 0.8900\n",
            "Epoch 12/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.3768 - acc: 0.8769 - val_loss: 0.2945 - val_acc: 0.9148\n",
            "Epoch 13/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.3240 - acc: 0.8972 - val_loss: 0.2516 - val_acc: 0.9307\n",
            "Epoch 14/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.2757 - acc: 0.9143 - val_loss: 0.2033 - val_acc: 0.9479\n",
            "Epoch 15/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.2326 - acc: 0.9295 - val_loss: 0.1958 - val_acc: 0.9411\n",
            "Epoch 16/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.1950 - acc: 0.9422 - val_loss: 0.1607 - val_acc: 0.9550\n",
            "Epoch 17/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.1617 - acc: 0.9537 - val_loss: 0.2043 - val_acc: 0.9329\n",
            "Epoch 18/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.1329 - acc: 0.9644 - val_loss: 0.1082 - val_acc: 0.9727\n",
            "Epoch 19/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1102 - acc: 0.9703 - val_loss: 0.0806 - val_acc: 0.9821\n",
            "Epoch 20/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0890 - acc: 0.9782 - val_loss: 0.0681 - val_acc: 0.9869\n",
            "Epoch 21/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0745 - acc: 0.9818 - val_loss: 0.0503 - val_acc: 0.9935\n",
            "Epoch 22/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0616 - acc: 0.9868 - val_loss: 0.0301 - val_acc: 0.9976\n",
            "Epoch 23/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0495 - acc: 0.9892 - val_loss: 0.0245 - val_acc: 0.9976\n",
            "Epoch 24/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0431 - acc: 0.9905 - val_loss: 0.0211 - val_acc: 0.9981\n",
            "Epoch 25/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0346 - acc: 0.9931 - val_loss: 0.0148 - val_acc: 0.9991\n",
            "Epoch 26/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0319 - acc: 0.9931 - val_loss: 0.0278 - val_acc: 0.9953\n",
            "Epoch 27/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0258 - acc: 0.9952 - val_loss: 0.0127 - val_acc: 0.9991\n",
            "Epoch 28/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0229 - acc: 0.9954 - val_loss: 0.0098 - val_acc: 0.9993\n",
            "Epoch 29/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0216 - acc: 0.9952 - val_loss: 0.0088 - val_acc: 0.9994\n",
            "Epoch 30/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0200 - acc: 0.9957 - val_loss: 0.0097 - val_acc: 0.9994\n",
            "Epoch 31/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0182 - acc: 0.9957 - val_loss: 0.0154 - val_acc: 0.9967\n",
            "Epoch 32/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0166 - acc: 0.9959 - val_loss: 0.0125 - val_acc: 0.9973\n",
            "Epoch 33/50\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.0144 - acc: 0.9966 - val_loss: 0.0048 - val_acc: 0.9997\n",
            "Epoch 34/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0128 - acc: 0.9971 - val_loss: 0.0056 - val_acc: 0.9997\n",
            "Epoch 35/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0140 - acc: 0.9967 - val_loss: 0.0080 - val_acc: 0.9982\n",
            "Epoch 36/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0124 - acc: 0.9969 - val_loss: 0.0028 - val_acc: 0.9998\n",
            "Epoch 37/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0121 - acc: 0.9969 - val_loss: 0.0048 - val_acc: 0.9995\n",
            "Epoch 38/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0117 - acc: 0.9971 - val_loss: 0.0042 - val_acc: 0.9993\n",
            "Epoch 39/50\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.0097 - acc: 0.9976 - val_loss: 0.0039 - val_acc: 0.9992\n",
            "Epoch 40/50\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.0102 - acc: 0.9973 - val_loss: 0.0062 - val_acc: 0.9987\n",
            "Epoch 41/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0098 - acc: 0.9975 - val_loss: 0.0099 - val_acc: 0.9972\n",
            "Epoch 42/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0085 - acc: 0.9979 - val_loss: 0.0196 - val_acc: 0.9942\n",
            "Epoch 43/50\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.0092 - acc: 0.9976 - val_loss: 0.0031 - val_acc: 0.9995\n",
            "Epoch 44/50\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.0100 - acc: 0.9972 - val_loss: 0.0028 - val_acc: 0.9995\n",
            "Epoch 45/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0090 - acc: 0.9975 - val_loss: 0.0063 - val_acc: 0.9982\n",
            "Epoch 46/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0086 - acc: 0.9976 - val_loss: 0.0050 - val_acc: 0.9991\n",
            "Epoch 47/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0091 - acc: 0.9974 - val_loss: 0.0020 - val_acc: 0.9998\n",
            "Epoch 48/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0075 - acc: 0.9979 - val_loss: 0.0066 - val_acc: 0.9987\n",
            "Epoch 49/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0081 - acc: 0.9979 - val_loss: 0.0011 - val_acc: 0.9999\n",
            "Epoch 50/50\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0074 - acc: 0.9977 - val_loss: 0.0014 - val_acc: 0.9999\n"
          ]
        }
      ],
      "source": [
        "#<Train your model on the entire training set (50K samples)>\n",
        "history = model2.fit(x_train, y_train_vec, batch_size=100, epochs=50, validation_data=(x_val, y_val))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMpREKvlwBaw"
      },
      "source": [
        "## 5. Evaluate the model on the test set (5 points)\n",
        "\n",
        "Do NOT use the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7fBiXSkwBaw",
        "outputId": "e2385f8e-e5c2-4a10-8468-21838f9bd5f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 3.1781 - acc: 0.6475\n",
            "loss = 3.1781058311462402\n",
            "accuracy = 0.6474999785423279\n"
          ]
        }
      ],
      "source": [
        "# Evaluate your model performance (testing accuracy) on testing data.\n",
        "\n",
        "loss_and_acc = model2.evaluate(x_test, y_test_vec)\n",
        "print(\"loss = \" + str(loss_and_acc[0]))\n",
        "print(\"accuracy = \" + str(loss_and_acc[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGWpuxepwBaw"
      },
      "source": [
        "## 6. Building model with new structure (25 points)\n",
        "- In this section, you can build your model with adding new layers (e.g, BN layer or dropout layer, ...).\n",
        "- If you want to regularize a ```Conv/Dense layer```, you should place a ```Dropout layer``` before the ```Conv/Dense layer```.\n",
        "- You can try to compare their loss curve and testing accuracy and analyze your findings.\n",
        "- You need to try at lease two different model structures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xDQrnyMfwBaw",
        "outputId": "6f827b26-582e-471b-8755-d670fe35daeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "500/500 [==============================] - 5s 7ms/step - loss: 1.5044 - acc: 0.4669 - val_loss: 1.2979 - val_acc: 0.5399\n",
            "Epoch 2/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 1.1582 - acc: 0.5931 - val_loss: 1.0864 - val_acc: 0.6145\n",
            "Epoch 3/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 1.0154 - acc: 0.6469 - val_loss: 0.9799 - val_acc: 0.6590\n",
            "Epoch 4/50\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.9152 - acc: 0.6819 - val_loss: 0.8502 - val_acc: 0.7057\n",
            "Epoch 5/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.8421 - acc: 0.7075 - val_loss: 0.8143 - val_acc: 0.7183\n",
            "Epoch 6/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.7812 - acc: 0.7290 - val_loss: 0.7492 - val_acc: 0.7388\n",
            "Epoch 7/50\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.7266 - acc: 0.7500 - val_loss: 0.6666 - val_acc: 0.7701\n",
            "Epoch 8/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.6787 - acc: 0.7687 - val_loss: 0.6442 - val_acc: 0.7744\n",
            "Epoch 9/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.6364 - acc: 0.7826 - val_loss: 0.6251 - val_acc: 0.7807\n",
            "Epoch 10/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.5963 - acc: 0.7982 - val_loss: 0.5560 - val_acc: 0.8152\n",
            "Epoch 11/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.5583 - acc: 0.8114 - val_loss: 0.5018 - val_acc: 0.8362\n",
            "Epoch 12/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.5207 - acc: 0.8261 - val_loss: 0.4706 - val_acc: 0.8466\n",
            "Epoch 13/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.4900 - acc: 0.8366 - val_loss: 0.4927 - val_acc: 0.8348\n",
            "Epoch 14/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.4559 - acc: 0.8499 - val_loss: 0.4523 - val_acc: 0.8457\n",
            "Epoch 15/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.4255 - acc: 0.8627 - val_loss: 0.3832 - val_acc: 0.8799\n",
            "Epoch 16/50\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.3990 - acc: 0.8725 - val_loss: 0.3887 - val_acc: 0.8716\n",
            "Epoch 17/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.3704 - acc: 0.8821 - val_loss: 0.3316 - val_acc: 0.9006\n",
            "Epoch 18/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.3445 - acc: 0.8925 - val_loss: 0.3578 - val_acc: 0.8801\n",
            "Epoch 19/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.3203 - acc: 0.9005 - val_loss: 0.2891 - val_acc: 0.9196\n",
            "Epoch 20/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.2977 - acc: 0.9109 - val_loss: 0.2767 - val_acc: 0.9192\n",
            "Epoch 21/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.2745 - acc: 0.9192 - val_loss: 0.2743 - val_acc: 0.9134\n",
            "Epoch 22/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.2546 - acc: 0.9263 - val_loss: 0.2642 - val_acc: 0.9107\n",
            "Epoch 23/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.2357 - acc: 0.9324 - val_loss: 0.2594 - val_acc: 0.9235\n",
            "Epoch 24/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.2175 - acc: 0.9405 - val_loss: 0.1738 - val_acc: 0.9614\n",
            "Epoch 25/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1983 - acc: 0.9471 - val_loss: 0.1694 - val_acc: 0.9606\n",
            "Epoch 26/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1816 - acc: 0.9525 - val_loss: 0.1847 - val_acc: 0.9491\n",
            "Epoch 27/50\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.1665 - acc: 0.9590 - val_loss: 0.1323 - val_acc: 0.9740\n",
            "Epoch 28/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1535 - acc: 0.9634 - val_loss: 0.1279 - val_acc: 0.9731\n",
            "Epoch 29/50\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.1408 - acc: 0.9667 - val_loss: 0.1278 - val_acc: 0.9715\n",
            "Epoch 30/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1257 - acc: 0.9720 - val_loss: 0.1064 - val_acc: 0.9799\n",
            "Epoch 31/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1148 - acc: 0.9758 - val_loss: 0.1203 - val_acc: 0.9733\n",
            "Epoch 32/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1053 - acc: 0.9789 - val_loss: 0.1059 - val_acc: 0.9772\n",
            "Epoch 33/50\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.0954 - acc: 0.9818 - val_loss: 0.1312 - val_acc: 0.9650\n",
            "Epoch 34/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0862 - acc: 0.9843 - val_loss: 0.1109 - val_acc: 0.9745\n",
            "Epoch 35/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0774 - acc: 0.9867 - val_loss: 0.0925 - val_acc: 0.9780\n",
            "Epoch 36/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0703 - acc: 0.9884 - val_loss: 0.0646 - val_acc: 0.9910\n",
            "Epoch 37/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0636 - acc: 0.9903 - val_loss: 0.0673 - val_acc: 0.9882\n",
            "Epoch 38/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0576 - acc: 0.9913 - val_loss: 0.0687 - val_acc: 0.9897\n",
            "Epoch 39/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0545 - acc: 0.9922 - val_loss: 0.0522 - val_acc: 0.9925\n",
            "Epoch 40/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0477 - acc: 0.9934 - val_loss: 0.0559 - val_acc: 0.9900\n",
            "Epoch 41/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0437 - acc: 0.9944 - val_loss: 0.0342 - val_acc: 0.9977\n",
            "Epoch 42/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0385 - acc: 0.9954 - val_loss: 0.0305 - val_acc: 0.9978\n",
            "Epoch 43/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0355 - acc: 0.9955 - val_loss: 0.0256 - val_acc: 0.9984\n",
            "Epoch 44/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0322 - acc: 0.9963 - val_loss: 0.0444 - val_acc: 0.9928\n",
            "Epoch 45/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0295 - acc: 0.9967 - val_loss: 0.0310 - val_acc: 0.9964\n",
            "Epoch 46/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0267 - acc: 0.9972 - val_loss: 0.0234 - val_acc: 0.9986\n",
            "Epoch 47/50\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 0.0251 - acc: 0.9972 - val_loss: 0.0171 - val_acc: 0.9997\n",
            "Epoch 48/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0223 - acc: 0.9976 - val_loss: 0.0219 - val_acc: 0.9972\n",
            "Epoch 49/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0213 - acc: 0.9978 - val_loss: 0.0261 - val_acc: 0.9961\n",
            "Epoch 50/50\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0192 - acc: 0.9981 - val_loss: 0.0172 - val_acc: 0.9987\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.4592 - acc: 0.7122\n",
            "loss = 1.4592257738113403\n",
            "accuracy = 0.7121999859809875\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation\n",
        "#BATCH NORMALIZATION\n",
        "model3 = models.Sequential()\n",
        "#1 conv, BN relu, max pool\n",
        "model3.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3)))\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(Activation('relu'))\n",
        "model3.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "#2 conv, BN, relu, max pool\n",
        "model3.add(Conv2D(64, (4, 4)))\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(Activation('relu'))\n",
        "model3.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model3.add(Flatten())\n",
        "\n",
        "\n",
        "\n",
        "#Dense layers\n",
        "model3.add(Dense(256, activation = 'relu'))\n",
        "model3.add(Dense(10, activation = 'softmax'))\n",
        "\n",
        "#Optimizer\n",
        "model3.compile(optimizer=optimizers.RMSprop(learning_rate=0.0001), loss = 'categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "\n",
        "#Train\n",
        "history = model3.fit(x_train, y_train_vec, batch_size=100, epochs=50, validation_data=(x_val, y_val))\n",
        "\n",
        "# Evaluate your model performance (testing accuracy) on testing data.\n",
        "loss_and_acc = model3.evaluate(x_test, y_test_vec)\n",
        "print(\"loss = \" + str(loss_and_acc[0]))\n",
        "print(\"accuracy = \" + str(loss_and_acc[1]))\n",
        "\n",
        "# Plot the loss curve\n",
        "%matplotlib inline\n",
        "\n",
        "epochs = range(50)\n",
        "train_acc = history.history['acc']\n",
        "valid_acc = history.history['val_acc']\n",
        "plt.plot(epochs, train_acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, valid_acc, 'r', label='Validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ElSZC9uWwBax",
        "outputId": "beb49102-d503-4979-acd6-8802a057c166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "500/500 [==============================] - 34s 64ms/step - loss: 1.7362 - acc: 0.3847 - val_loss: 1.5392 - val_acc: 0.4696\n",
            "Epoch 2/50\n",
            "500/500 [==============================] - 31s 62ms/step - loss: 1.5390 - acc: 0.4693 - val_loss: 1.4204 - val_acc: 0.5104\n",
            "Epoch 3/50\n",
            "500/500 [==============================] - 31s 62ms/step - loss: 1.4555 - acc: 0.5064 - val_loss: 1.3048 - val_acc: 0.5620\n",
            "Epoch 4/50\n",
            "500/500 [==============================] - 31s 61ms/step - loss: 1.4027 - acc: 0.5295 - val_loss: 1.2875 - val_acc: 0.5510\n",
            "Epoch 5/50\n",
            "500/500 [==============================] - 32s 65ms/step - loss: 1.3559 - acc: 0.5446 - val_loss: 1.2208 - val_acc: 0.5928\n",
            "Epoch 6/50\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 1.3224 - acc: 0.5570 - val_loss: 1.2141 - val_acc: 0.5865\n",
            "Epoch 7/50\n",
            "500/500 [==============================] - 31s 63ms/step - loss: 1.2901 - acc: 0.5682 - val_loss: 1.1516 - val_acc: 0.6064\n",
            "Epoch 8/50\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 1.2596 - acc: 0.5816 - val_loss: 1.1132 - val_acc: 0.6291\n",
            "Epoch 9/50\n",
            "500/500 [==============================] - 32s 64ms/step - loss: 1.2338 - acc: 0.5932 - val_loss: 1.1000 - val_acc: 0.6302\n",
            "Epoch 10/50\n",
            "500/500 [==============================] - 30s 61ms/step - loss: 1.2107 - acc: 0.5979 - val_loss: 1.0877 - val_acc: 0.6362\n",
            "Epoch 11/50\n",
            "500/500 [==============================] - 33s 67ms/step - loss: 1.1906 - acc: 0.6030 - val_loss: 1.0329 - val_acc: 0.6535\n",
            "Epoch 12/50\n",
            "500/500 [==============================] - 31s 61ms/step - loss: 1.1748 - acc: 0.6106 - val_loss: 1.0284 - val_acc: 0.6500\n",
            "Epoch 13/50\n",
            "500/500 [==============================] - 32s 64ms/step - loss: 1.1569 - acc: 0.6151 - val_loss: 1.0389 - val_acc: 0.6521\n",
            "Epoch 14/50\n",
            "500/500 [==============================] - 31s 61ms/step - loss: 1.1376 - acc: 0.6209 - val_loss: 0.9275 - val_acc: 0.6982\n",
            "Epoch 15/50\n",
            "500/500 [==============================] - 32s 65ms/step - loss: 1.1227 - acc: 0.6273 - val_loss: 0.9534 - val_acc: 0.6776\n",
            "Epoch 16/50\n",
            "500/500 [==============================] - 30s 61ms/step - loss: 1.1063 - acc: 0.6310 - val_loss: 0.9759 - val_acc: 0.6733\n",
            "Epoch 17/50\n",
            "500/500 [==============================] - 32s 64ms/step - loss: 1.0955 - acc: 0.6355 - val_loss: 1.0243 - val_acc: 0.6562\n",
            "Epoch 18/50\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 1.0801 - acc: 0.6376 - val_loss: 0.9200 - val_acc: 0.6917\n",
            "Epoch 19/50\n",
            "500/500 [==============================] - 33s 67ms/step - loss: 1.0659 - acc: 0.6448 - val_loss: 0.9838 - val_acc: 0.6626\n",
            "Epoch 20/50\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 1.0551 - acc: 0.6468 - val_loss: 0.8249 - val_acc: 0.7291\n",
            "Epoch 21/50\n",
            "500/500 [==============================] - 33s 66ms/step - loss: 1.0415 - acc: 0.6512 - val_loss: 0.8650 - val_acc: 0.7100\n",
            "Epoch 22/50\n",
            "500/500 [==============================] - 32s 64ms/step - loss: 1.0326 - acc: 0.6553 - val_loss: 0.8612 - val_acc: 0.7080\n",
            "Epoch 23/50\n",
            "500/500 [==============================] - 31s 62ms/step - loss: 1.0188 - acc: 0.6569 - val_loss: 1.0397 - val_acc: 0.6470\n",
            "Epoch 24/50\n",
            "500/500 [==============================] - 31s 63ms/step - loss: 1.0101 - acc: 0.6615 - val_loss: 0.8585 - val_acc: 0.7097\n",
            "Epoch 25/50\n",
            "500/500 [==============================] - 31s 62ms/step - loss: 1.0029 - acc: 0.6619 - val_loss: 0.8786 - val_acc: 0.6996\n",
            "Epoch 26/50\n",
            "500/500 [==============================] - 32s 64ms/step - loss: 0.9942 - acc: 0.6650 - val_loss: 0.9598 - val_acc: 0.6792\n",
            "Epoch 27/50\n",
            "500/500 [==============================] - 31s 63ms/step - loss: 0.9915 - acc: 0.6647 - val_loss: 0.8862 - val_acc: 0.7019\n",
            "Epoch 28/50\n",
            "500/500 [==============================] - 31s 63ms/step - loss: 0.9795 - acc: 0.6693 - val_loss: 0.8457 - val_acc: 0.7223\n",
            "Epoch 29/50\n",
            "500/500 [==============================] - 32s 64ms/step - loss: 0.9672 - acc: 0.6749 - val_loss: 0.8220 - val_acc: 0.7226\n",
            "Epoch 30/50\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.9609 - acc: 0.6776 - val_loss: 0.8157 - val_acc: 0.7192\n",
            "Epoch 31/50\n",
            "500/500 [==============================] - 32s 65ms/step - loss: 0.9538 - acc: 0.6789 - val_loss: 0.8379 - val_acc: 0.7184\n",
            "Epoch 32/50\n",
            "500/500 [==============================] - 30s 61ms/step - loss: 0.9488 - acc: 0.6789 - val_loss: 0.7755 - val_acc: 0.7344\n",
            "Epoch 33/50\n",
            "500/500 [==============================] - 32s 65ms/step - loss: 0.9476 - acc: 0.6788 - val_loss: 0.8064 - val_acc: 0.7260\n",
            "Epoch 34/50\n",
            "500/500 [==============================] - 31s 62ms/step - loss: 0.9315 - acc: 0.6847 - val_loss: 0.7514 - val_acc: 0.7465\n",
            "Epoch 35/50\n",
            "500/500 [==============================] - 33s 65ms/step - loss: 0.9275 - acc: 0.6861 - val_loss: 0.7527 - val_acc: 0.7480\n",
            "Epoch 36/50\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.9245 - acc: 0.6861 - val_loss: 0.7642 - val_acc: 0.7350\n",
            "Epoch 37/50\n",
            "500/500 [==============================] - 33s 65ms/step - loss: 0.9188 - acc: 0.6892 - val_loss: 0.7943 - val_acc: 0.7322\n",
            "Epoch 38/50\n",
            "500/500 [==============================] - 30s 61ms/step - loss: 0.9117 - acc: 0.6899 - val_loss: 0.7973 - val_acc: 0.7347\n",
            "Epoch 39/50\n",
            "500/500 [==============================] - 32s 64ms/step - loss: 0.9143 - acc: 0.6898 - val_loss: 0.7243 - val_acc: 0.7545\n",
            "Epoch 40/50\n",
            "500/500 [==============================] - 30s 61ms/step - loss: 0.9013 - acc: 0.6923 - val_loss: 0.7577 - val_acc: 0.7430\n",
            "Epoch 41/50\n",
            "500/500 [==============================] - 32s 64ms/step - loss: 0.8957 - acc: 0.6942 - val_loss: 0.6995 - val_acc: 0.7625\n",
            "Epoch 42/50\n",
            "500/500 [==============================] - 31s 63ms/step - loss: 0.8934 - acc: 0.6957 - val_loss: 0.7260 - val_acc: 0.7557\n",
            "Epoch 43/50\n",
            "500/500 [==============================] - 31s 62ms/step - loss: 0.8857 - acc: 0.6987 - val_loss: 0.7610 - val_acc: 0.7423\n",
            "Epoch 44/50\n",
            "500/500 [==============================] - 32s 63ms/step - loss: 0.8861 - acc: 0.6998 - val_loss: 0.7079 - val_acc: 0.7586\n",
            "Epoch 45/50\n",
            "500/500 [==============================] - 31s 63ms/step - loss: 0.8773 - acc: 0.7014 - val_loss: 0.7357 - val_acc: 0.7527\n",
            "Epoch 46/50\n",
            "500/500 [==============================] - 31s 63ms/step - loss: 0.8805 - acc: 0.6999 - val_loss: 0.7199 - val_acc: 0.7502\n",
            "Epoch 47/50\n",
            "500/500 [==============================] - 31s 63ms/step - loss: 0.8709 - acc: 0.7029 - val_loss: 0.7405 - val_acc: 0.7450\n",
            "Epoch 48/50\n",
            "500/500 [==============================] - 33s 66ms/step - loss: 0.8689 - acc: 0.7043 - val_loss: 0.6917 - val_acc: 0.7692\n",
            "Epoch 49/50\n",
            "500/500 [==============================] - 32s 64ms/step - loss: 0.8567 - acc: 0.7079 - val_loss: 0.6617 - val_acc: 0.7737\n",
            "Epoch 50/50\n",
            "500/500 [==============================] - 30s 61ms/step - loss: 0.8562 - acc: 0.7075 - val_loss: 0.6550 - val_acc: 0.7803\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7432 - acc: 0.7490\n",
            "loss = 0.743191659450531\n",
            "accuracy = 0.7490000128746033\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAA5iklEQVR4nO3dd3hUZdr48e9NkI5Is9FxKdJLRAULFhQssO7KCvK6oL4iVlZZFRsqyk9dfdfuruhaVliRVcHYBRsIigQBFRAIECCI0gSpgZD798dzJhmSmclMMieTzNyf65pr5jynPYcM557zVFFVjDHGmKKqJDoDxhhjKiYLEMYYY0KyAGGMMSYkCxDGGGNCsgBhjDEmJAsQxhhjQvI1QIhIfxFZLiJZIjI2xPrmIvKZiCwUke9E5Lygdbd7+y0XkXP9zKcxxpjixK9+ECKSBqwA+gE5wHxgqKouDdpmIrBQVf8hIh2A91W1pff5NaAXcCwwE2irqgd9yawxxphi/HyC6AVkqepqVd0PTAEGFdlGgcO9z/WAn7zPg4ApqpqrqmuALO94xhhjyklVH4/dBFgftJwDnFhkm3uBj0XkBqA2cHbQvl8X2bdJ0ROIyEhgJEDt2rV7tm/fPi4ZN8aYVLFgwYItqto41Do/A0Q0hgIvq+r/icjJwKsi0inanVV1IjARID09XTMzM33KpjHGJCcRWRtunZ8BYgPQLGi5qZcW7EqgP4CqfiUiNYBGUe5rjDHGR37WQcwH2ohIKxGpBgwBMopssw44C0BEjgdqAJu97YaISHURaQW0Ab7xMa/GGGOK8O0JQlXzROR64CMgDXhRVZeIyHggU1UzgDHA8yJyE67CeoS6ZlVLRGQqsBTIA66zFkzGGFO+fGvmWt5C1UEcOHCAnJwc9u3bl6BcmZLUqFGDpk2bcthhhyU6K8akJBFZoKrpodYlupLaVzk5OdStW5eWLVsiIonOjilCVdm6dSs5OTm0atUq0dkxxhSR1ENt7Nu3j4YNG1pwqKBEhIYNG9oTnjEVVFIHCMCCQwVnfx9jKq6kDxDGGJO0VOHNN+GFF3w5vAUIH23dupVu3brRrVs3jj76aJo0aVKwvH///oj7ZmZmcuONN5Z4jt69e8cru8aYyuSTT6BXL7j4YvjXv1ywiDMLEEEmT4aWLaFKFfc+eXLZjtewYUMWLVrEokWLGDVqFDfddFPBcrVq1cjLywu7b3p6Ok8++WSJ55g7d27ZMmmMqVzmz4d+/eDss2HTJnjpJfjyS/ChuNYChGfyZBg5EtaudYF47Vq3XNYgUdSIESMYNWoUJ554IrfeeivffPMNJ598Mt27d6d3794sX74cgM8//5wLLrgAgHvvvZcrrriCvn370rp160MCR506dQq279u3LxdffDHt27dn2LBhBJowv//++7Rv356ePXty4403Fhw3WHZ2Nqeeeio9evSgR48ehwSehx9+mM6dO9O1a1fGjnWjtmdlZXH22WfTtWtXevTowapVq+L7D2WMOdTSpTB4sHtqWLQIHn8cVqyAESMgLc2XUyZ1M9dY3Hkn7NlzaNqePS592LD4nisnJ4e5c+eSlpbGb7/9xuzZs6latSozZ87kjjvu4M033yy2z48//shnn33Gzp07adeuHddcc02xvgMLFy5kyZIlHHvssfTp04c5c+aQnp7O1VdfzaxZs2jVqhVDhw4NmacjjzySGTNmUKNGDVauXMnQoUPJzMzkgw8+4O2332bevHnUqlWLbdu2ATBs2DDGjh3LRRddxL59+8jPz4/vP5IxBrZsgddfh1dfhXnzoE4duPdeuPlmqFvX99NbgPCsWxdbelkMHjyYNC/i79ixg+HDh7Ny5UpEhAMHDoTc5/zzz6d69epUr16dI488kl9++YWmTZsesk2vXr0K0rp160Z2djZ16tShdevWBf0Mhg4dysSJE4sd/8CBA1x//fUsWrSItLQ0VqxYAcDMmTO5/PLLqVWrFgANGjRg586dbNiwgYsuughwnd2MMXGybx+8844LCh98AHl50LUrPPIIDB8OjUMOvOoLCxCe5s1dsVKo9HirXbt2wee7776bM844g2nTppGdnU3fvn1D7lO9evWCz2lpaSHrL6LZJpzHHnuMo446isWLF5Ofn283fWMSYf16OOEE+OUXOPZYuOkmuOwy6Nw5IdmxOgjPhAng/UguUKuWS/fTjh07aNLETXXx8ssvx/347dq1Y/Xq1WRnZwPw+uuvh83HMcccQ5UqVXj11Vc5eNANfdWvXz9eeukl9njlb9u2baNu3bo0bdqU6dOnA5Cbm1uw3hhTBvffD7/+6p4c1q2Dv/0tYcEBLEAUGDYMJk6EFi1cY4AWLdxyvOsfirr11lu5/fbb6d69e0y/+KNVs2ZNnn32Wfr370/Pnj2pW7cu9erVK7bdtddeyyuvvELXrl358ccfC55y+vfvz8CBA0lPT6dbt248+uijALz66qs8+eSTdOnShd69e/Pzzz/HPe/GpJRVq1yLpKuvhv79fat4jkVSD9a3bNkyjj/++ATlqOLYtWsXderUQVW57rrraNOmDTfddFOis1XA/k7GV59/7ip4r7kGDj+8xM0TZvhwmDoVVq+GY44pt9NGGqzPniBSwPPPP0+3bt3o2LEjO3bs4Oqrr050lowpH1u2uKahY8fCccfB009DmIYgCfXjjzBpElx/fbkGh5JYgEgBgQ56S5cuZfLkyQUtkoxJejffDNu3uw5NnTrBDTdAx45ueIpYS08OHoS774bnn4fc3Pjm8957oWZNuPXW+B63jCxAGGOS08cfu6aiY8fCpZfCp5/Ce+9BtWpueIrevWHOnOiP98AD7jVyJLRuDX//O+zaVfZ8fved6+vwl7+UaxPWaPgaIESkv4gsF5EsERkbYv1jIrLIe60Qke1B6w4GrSs6VakxJhXl58PDD8PChZG3270bRo2Cdu1cb1dwrU/OOw8WL3aD261bB6ee6m7OJZkxA+67zzU5nTHDHXfMGNea5b77wOtAWir33AP16rnjVTSq6ssLN83oKqA1UA1YDHSIsP0NuGlJA8u7Yjlfz549tailS5cWSzMVj/2dTNSefVYVVOvUUf3kk/DbjRnjtvvii/Db7NypeuqpqocdpvrBB+G3W79etVEj1Y4dVXftKkz/6ivVgQML8/PnP6s+9ZTq3Lmqu3dHdz3z57v9x4+Pbnsf4KaADn1fDreirC/gZOCjoOXbgdsjbD8X6Be0bAEiRdjfyURlwwbVww93N/WOHVWrVVOdNq34dpmZqlWqqF51VcnH3L5dtVs31Zo1VefMKb5+/37V3r1dAFi2LPQxvvtO9bLLVI86yt1SQTUtTbVzZ9URI1RffPHQwBJswADVBg1Ud+woOa8+SVSAuBh4IWj5MuDpMNu2ADYCaUFpeUAm8DXw+zD7jfS2yWzevHmxC0/0jadv37764YcfHpL22GOP6ahRo8Luc/rpp+v8+fNVVXXAgAH666+/Ftvmnnvu0UceeSTiuadNm6ZLliwpWL777rt1xowZMeS+/CT672TKKD9f9eefVefNU33rLdWNG/05z8UXq9aoobpyperWraonneQCwYsvFm5z4IBq9+6qRx+tGuL/Tkg//6zapo3qEUeoLl586LrAk8hrr5V8nPx81Zwc1bffVr37btXzzlM98ki3f716qqNHqy5fXrj9nDlu3cMPR5dPn1SGAHEb8FSRtCbee2sgGzgu0vkq4hPEc889pyNGjDgk7cQTT9QvIjz2BgeIcKIJEMOHD9f//ve/0Wc2gRL9dzIx2r9f9fbbVfv1U23b1t20A7+cQbVpU9U1a+J7znfecceeMKEwbdcu1XPOcemPPurS/vY3t/zGG7EdPztbtUkT9xSQleXS3nrLHeu660qf7/x8FwguvdQVZYH7d5s+XfWMM1wACfd0UU4qfBETsBDoHeFYLwMXRzpfRQwQW7du1caNG2tubq6qqq5Zs0abNWum+fn5OmrUKO3Zs6d26NBBx40bV7BPcIBo0aKFbt68WVVVH3jgAW3Tpo326dNHhwwZUhAgJk6cqOnp6dqlSxf9wx/+oLt379Y5c+Zo/fr1tWXLltq1a1fNyso6JGDMnDlTu3Xrpp06ddLLL79c9+3bV3C+cePGaffu3bVTp066LMQj9Zo1a/SUU07R7t27a/fu3XVO0GP5Qw89pJ06ddIuXbrobbfdpqqqK1eu1LPOOku7dOmi3bt316zAf74gif47mRg98oi7dfTs6X7Vjxnjyt4zMlTff1+1fn3V1q3dr+l42LlTtXlzV6zk/V8qsG+f6uDBLj9XX+2KigYNcjfmWC1ZotqwoWqrVqqzZrnirBNOcOeIh59/Vr3/fhdAA8H08cfjc+wySFSAqAqsBloFVVJ3DLFde+8JQYLS6gPVvc+NgJWRKrg1mgAxerTq6afH9zV6dIn/+Oeff75Onz5dVVUffPBBHTNmjKq64KGqmpeXp6effrou9h5tQwWIzMxM7dSpk+7evVt37Nihxx13XEGA2LJlS8G57rzzTn3yySdVtfgTRGB579692rRpU13uPepedtll+thjjxWcL7D/M888o1deeWWx69m9e7fu3btXVVVXrFihgX/3999/X08++WTd7VXOBa6vV69e+tZbb6mq6t69ewvWB7MAUYmsX69au7bqBReE32bePNW6dVXbt1fdtKns57z5Zner+vLL0Ovz8lxwAHfesgSmb75x9Q3gAl28n4RUXTHYm2+qjh2r6v1fSqRIAcK3Zq6qmgdcD3wELAOmquoSERkvIgODNh0CTPEyGnA8kCkii4HPgIdUdalfefXT0KFDmTJlCgBTpkwpmI9h6tSp9OjRg+7du7NkyRKWLg1/ebNnz+aiiy6iVq1aHH744QwcWPjP98MPP3DqqafSuXNnJk+ezJIlSyLmZ/ny5bRq1Yq2bdsCMHz4cGbNmlWw/g9/+AMAPXv2LBjgL9iBAwe46qqr6Ny5M4MHDy7Id7TDglsnvUru5ptdh7FIsx326gXvvuuGR+7Xzw0+V1oLF7qJca6+Gvr0Cb1NWhr84x/wzDNuqApv8MtSOeEEePttaNXK9Wxu2bL0xwqnalX4wx/gwQehgo+a7Otw36r6PvB+kbRxRZbvDbHfXCC+Qxg+/nhcDxetQYMGcdNNN/Htt9+yZ88eevbsyZo1a3j00UeZP38+9evXZ8SIEezbt69Uxx8xYgTTp0+na9euvPzyy3z++edlym9gyPBww4XbsOAp7OOP4b//dSOOevOLhHXaaTB9Olx4IQwY4PoOxDrBzcGDrlNa48buZhqJCFx7bWzHD+fMM914SMZ6UvutTp06nHHGGVxxxRUFTw+//fYbtWvXpl69evzyyy988MEHEY9x2mmnMX36dPbu3cvOnTt55513Ctbt3LmTY445hgMHDjA5aH7UunXrsnPnzmLHateuHdnZ2WRlZQFuVNbTTz896uuxYcFTVG6uGyeoTRu45Zbo9jnnHPeLPjMTLrig+JSNJXn6abfvE09A/fqx59mUmQWIcjB06FAWL15cECC6du1K9+7dad++PZdeeil9wj06e3r06MEll1xC165dGTBgACeccELBuvvvv58TTzyRPn360L59+4L0IUOG8Mgjj9C9e/dD5ouuUaMGL730EoMHD6Zz585UqVKFUaNGRX0tNix4Evr+e3jsMTeTWTiPPAIrV7qbdtDEVCUaNMgNdzF7NvToATfeCFOmuF7Mh5Qq45ZXrXJB5dZb4a673NPHn/5UuusyZWbDfZuEs79TAm3a5G7cGzbA8cfDK6+4cvhga9ZAhw6uuGjq1NKd5403XB3BN98UPkkce6wbD6l5czf8xbffFtZXVKvm6jImTXLDWRjf2HDfxpji8vJgyBDYutU9Gfz2G5x8shuxdP/+wu1uvNFVBP/976U/18UXw2efwY4dsGABPPUUnH66K0J66ik34urgwW6WrgULYOdO99RhwSGhbE5qk5xyc90N6K9/dTcnU9xdd7mb9ssvu8lqhg1zI4o+8AC88457mli71rVIeuQRaNq07OesWtU9sfTo4eo0wA3AV8V+q1ZESf9XSZYitGTl29/n++/dLGIjR4LVexQ3fbobFXXkSBccAI44wgWLt992/2bp6XDFFW7+hNGj/cuLBYcKK6n/MjVq1GDr1q0WJCooVWXr1q3+NJVdtMi979jhJokxhVaudEEhPd21ECpq4EBYssQ9ee3YAc8+C4cdVv75NAmX1EVMTZs2JScnh82bNyc6KyaMGjVq0DQeRRdFLVrk5h8OtIZ56y3XOamy2brVVe5u3+7qBYJf+fnQs6drTtqli+sLUJLdu92/Q9WqruI4XHBu2BBee83Nm+C1VDOpJ6lbMZkUdsop7ob56aeuNczGjbB0KTRokOicxWbwYDc9Zp06rmVP8Csvz7UwAjjqKBcozjkHzj4bjj66+LFU4c9/dtNvfvih29akvEitmJL6CcKkqPx812xyxAhXNPLii67p5pgx8NJLic5d9D780P3KnzAB7rgj9DYbNrheyh9/DB984PocgKtPOOII18Es8H7woKtfGD/egoOJij1BmOSTleV6/L7wAlx5pUu74w43XMOHH8K55yY2f9HYtw86dXJFQYsXR9c5LT/fFa3NnAk5Oa5Y6tdfC99//dVd+wsvWMWwKWBPECa1LF7s3rt1K0wbNw6mTXOtdn74IfZxgcrbww+7XsUzZ0bfc7lKlcImpMbEgf2MMMln0SLXsatjx8K0GjXgX/+C9evDF9dUFFlZ7mln6FA466xE58ZUAJMnu4Flq1Rx70HDrvnKAoRJPosWuWEjirbQ6d3bNXl9+mnX3n/1alcsUxYbNhQfU6gsVF0HsmrV4P/+L37HNZXW5MnuwXftWvf1WLvWLU+e7H/gsABhks+iRdC1a+h1Eya4+onLL4fjjnNNOLt1g0svdcNYz58f/XkWLoRmzdwv/XiNUvvWW/DRRy4vxxwTn2OaSiPUDf/OO4t/vfbscX0XwwWOeLEAYZLLli2ugja4/iFYnTruxv7ll/D8824OgWOPhblzXT2FN7lRVGbPdv8zp051zWrXrStb3nftckNddO0K111XtmOZCivcr/5wTwpr14Y+ztatoQPHnXfGMbPhppqLxwvoDywHsoCxIdY/BizyXiuA7UHrhuOmGl0JDC/pXKGmHDUpaOZMN13kjBmx7/v4427fDRui2/7Pf3aT3L/3nmq9eqqNG6t+8UXs5w245RZ3/rlzS38M45tJk1RbtFAVce+TJsWePmmSaq1ahVNSg1sObBucHnilpYVOD/cSie26SNCc1GnAKqA1hXNSh51XGrgBeNH73AA3n3UD3PzUq4H6kc5nAcKoquqjj7qvdWnmQp4zx+379tvRbd+pk+p557nPP/6o2q6datWqqs8+G/u5v//e7fu//xv7viauYrmxX3NNbOkNG4a+qQfOF+6mH+uxYpGoAHEy8FHQ8u3A7RG2nwv08z4PBZ4LWvccMDTS+SxAGFVVvewy1SZNSrfv7t2qVaqo3nVX9NvefXdh2vbtLmCA6siRqrm50Z03P1/17LNVGzRQ3bKldHk3cREuEIS7GYf7dV+aX/3hniACQSqWp5FYRAoQftZBNAHWBy3neGnFiEgLoBXwaSz7ishIEckUkUwbbymBdu92rYJCzGFd7hYtCl//UJJatVzT2Gg6XC5e7FpABfc5qFcPMjLg9tvdvAZjxkR33o8/dv0d7rnHjYFk4iZSeX+o9HAVwlu3hj6+N+Nu1OnhNG/u2k/UqnVoeq1aLn3YMMjOdl+57Gy3PGyY+5q1aOFGlWnRwi0PGxbbuSMKFznK+gIuBl4IWr4MeDrMtrcBTwUt/xW4K2j5buCvkc5nTxAJ9NRT7ufLE08kNh9797pimjvvLP0xrrhCtVEj96s+ksA1r1sXev0NN7ife5mZkY+Tl6faubNq69bRP3GYYuJRLDRpUuRinng8QTRsGPlXf7j6DD9R0YuYgIVA76BlK2KqTAYOdF+lww9X/emnxOVjwQKXj6lTS3+MZ591x8jOjrzd5Ze7SulwgWT7dtWjj1Y94QQXBMJ56SV3vtdfL3WWk02km2QsgSDWYqEWLcIX84S7scdaBxHIb3kHgUgSFSCq4iqXW1FYSd0xxHbtgWy8caG8tAbAGlwFdX3vc4NI57MAkSD796vWravar59qtWqq//M//pwnNzf8r/WAf/3LfaVXrCj9eb75xh3jjTcib9eli2r//pG3+c9/3LH+8Y/Q6/fscfUlvXqV/MSShGItV481EMT6Ein5/GVtxVQRJSRAuPNyHq756irgTi9tPDAwaJt7gYdC7HsFrnlsFnB5SeeyAJEgs2cX3lDvust9/vzz+J/n7rtVa9aM/IRyww2qtWurHjxY+vPs26d62GGqt90Wfps9e9zP0DvuiHys/HzVM89UPeII1V9+Kb7+wQfdv1dZmsZWIPFo7hmpZU64X/exviI9QUS6jmSVsABRni8LEAkybpxrzbNtm2vZ06KFaseO7skiXg4eLLw73Htv+O1OPVW1d++yn69HD9Wzzgq//uuvXV7efLPkYy1b5gLO8OGHpm/a5IrkBg4sU1YTIR7l/bH+6heJvX4g1mKhZA8E4ViAMP45+WRXRBLw9tvua/Xoo/E7x5dfumPWq+fK9UNV5ubnuxvutdeW/XwjR7pzhSv2ibaeIuCOO7TYk8KNN7rAunRpmbNbnuJV3h/rqzT1A6UpFkpFFiCMP7Zvd3eA4FZD+fmq55+vWqeOak5OfM5z3XWqNWq4ymdQnTy5+DarV7t1EyeW/XzPP++OtXJl6PVXXunuStHWGxR9slq50rW2Gjmy7HktZ/Eq5on1V3809RN2wy8dCxDGH9Omua9Q0TqHVavcDf2SS8p+jgMHXGuhwYNdUVObNqonnVR8u7fecnn55puyn3PhQnes114Lvb5bN1cpH4uMDHfMRx5R/dOfXF1JObb4ilcFa7yagZbmV3+kfJnSswBh/HHtte5GF6rI57773Ndr5syynePDD91xpk1zy08+GToQBOpC9uwp2/lU3a/86tVVb765+LpAX4uxY2M/7sCBLnCC6j33lDmbofg5TESk8YJKU95vN/uKwQKE8UebNoVjERW1d6/qcce58Yn27i39Of78Z1cfsG+fW96xwxVfXXbZodsNHKh6/PGlP09RJ56oetppxdPnz3f/bf7739iPuWaNa4l11FGqv/1Wpuz52R8gUiufeDYDNRWDBQgTf9nZ7uvz+OPht3n/fbdNo0bup+QXX8TWBHXPHhcMrrji0PTrr3d9Ln7+uTCteXPVoUNju4ZIrrvOnbtoJ7d//tNd0+rVpTvuF1+4Dn1l4Hd/gHCvwCihdsNPLpEChM0HYUpnxgz33q9f+G0GDIAPPoAzz3RjNZ1+uhsw5q9/deMdqUY+x3vvuTkSLr300PTrr4f9+93AMwDbtrm5GEo7BlMoJ5zgzr1ixaHpCxZA/fpuAJ/SOO20Ms8ZHet4QeGkpcWW3ry5ew81LpBJThYgTOnMmOEm2jn++Mjb9e8Pr78Omza5EdG6d4cnn3Q34Guuibzvf/4DRx8Nffsemt6uHZx7Lvzzn3DggBs4D+IbINLT3XvRgfu+/dbd4EXid64wwg0oF+u8RA0bhh4EbuTI2NInTIjtvCYJhHu0qGwvK2IqRwcPuvKMop2/orV1qyvCidRS6NdfXTHS6NGh17/7rtt/yhTVxx5zn4OLnMoqL8+V29xwQ2Fabq7L0623xu88YZRmYpl49gewYqTUgdVBmLjKzHRfnbLcNfbvd53sDj88dHn+iy+6c8ybF3r/gwddJXjv3i5QHXNM6fMSzimnuDwGBAYDLOXAerHcjEuaG8BaBpl4sQBh4iswhlBZf7GvWeMCxEknFR+a4+yzXQCI1Bkt8ORQv37JA+eVxl/+4pqlHjjglidOdOcL14HOE4+mplZRbMqLBQgTX2ec4UYzjYcpU9zXMHjgu40bo5vZbft21w8DStcvoSSTJrljL17slkeNOmQIjkQ1NTUmniIFCKukNrHZswfmzInceikWl1wCV14JDz4In3oTCk6d6prIFG29VFS9ejB8uPsczwrqgBNOcO+BiuoFCwoqqCdPdpW5a9e6W/fatW559Oj4zUhmFcUm0SxAmNjMmuWamMYrQAA88QS0bQv/8z+wZYtrvdS1a8ktpABuuQXOPx/OOit++Qn43e/YX/NwXh2dSTU5QO7871hasyfgf1PTwPSRvk4naUwJLECY2MyYAdWqwamnxu+YtWvDlCnu7jpoEMybV/LTQ0DLlvDuu9CoUZmyEKpJ6eTXqvBVbk/a75pPB5ZQnVz+NrMHkyf739Q03DzExpSrcGVPle1ldRDlpHNnNwmOH554orCwfe1af84RQqR6g4e5RXM5TEfhhvhuw3IbetokFRI4o1x/YDluVrixYbb5E7AUWAL8Jyj9ILDIe2WUdC4LEKWwfXvhGEfR2LjRfWUefNCf/OTnu5FOf/97f46vsTUpBdXBvK4K+hUn6g7qqnCw1FNTGlMRJSRAAGm4qUZbUzgndYci27QBFgL1veUjg9btiuV8FiBitHq1mwqzdm030N2zz4YfXyg3V/X7711LIXD9ICqhcDf1SOMPtWR1wcJnnH5ISyILBCYZRAoQVX0sveoFZKnqagARmQIM8p4WAq4CnlHVXwFUdZOP+TEBeXmuQDs/31UMf/QRZGS4dW3buuExGjSAJUvghx9g5Uq3D0CrVm64jApu8mRXkbxunRtDaMKE8BXLaWmhWxM1bAib9rRk694GNGQb39LjkJZEw4ZZvYBJbn5WUjcB1gct53hpwdoCbUVkjoh8LSL9g9bVEJFML/33oU4gIiO9bTI3b94c18wntQcegK++gueec+MZrV4Ny5e71kTHHeeay9x3nxt3qE0b11Jo0iRYuBCWLXM1uRVAuLGKwjVBXbs29HHCNSl94gmY+LywpIYbl2ltw57WksiklnCPFmV9ARcDLwQtXwY8XWSbd4FpwGFAK1xAOcJb18R7bw1kA8dFOp8VMUVp9mzXCS3SOEp797ppMiuw0oxVVNI8B2GLiwJzSi9blpBrNcZPJKiIaQPQLGi5qZcWLAeYp6oHgDUisgJXLzFfVTcAqOpqEfkc6I6r0zCltX27+/nbqhU89VT47WrUKLcslVa44qJAsVIogSeF4P2Cm5SGfTIYNcoVubVrF5e8G1NZ+FlWMB9oIyKtRKQaMATIKLLNdKAvgIg0whU5rRaR+iJSPSi9D4fWXZhYqcLVV8NPP7mOaHXrJjpHZRIuCATqHEIpdeezZs1gzJhyGeLbmIrEtwChqnnA9cBHwDJgqqouEZHxIjLQ2+wjYKuILAU+A25R1a3A8UCmiCz20h9SVQsQZfHKK24Ii/vvh169Ep2bmISqawgXBAIV0tb5zJg4CFf2VNleVgcRwYoVrjnrGWcUn0KzAonHKKjW+cyY2BChDkLc+sovPT1dM4vO/mVg40a48EJYs8bNvNa0aaJzFFKg5VHR+oGaNUOPb9SiRWHT1eCmrPZEYExsRGSBqqaHWlcx2iua+Fu7Fq67zlVIL1oEL75YYYJDqCKjWAe/W7fOiouM8ZufrZhMIqxYAQ89BK++6ipVL78cbrsNWrdOdM6A4k8KgT4KRYNDScLVQRhj4scCRGWUnw/btsGmTfDLL4Xvc+bAG2+40VavvdZ1cEvgU0O8ejPv3Ru6aaoxxl8WICqbv/3N3WUDQ18Eq1vXBYWbboKjjir/vAWJ9UkhXB+FJ55wn62uwZjyZ5XUlUl2tuus1aePmzfhqKPc68gj3XuDBhVmGIyWLUMPbRHuScEqnY1JjEiV1PYEUZncdZcLAP/+d4WqcA51U497b2ZjTLmrGD83Tcm+/dbdjW+6qUIFh1CD4kXqyGZTaRpTeZRYxCQiFwLvqWp++WSpdJK6iEkVzj7b9WNYtQrq1Ut0joDwxUiB4qJQ/RosGBhTsZS1H8QlwEoR+ZuItI9v1kxUPvwQPv0Uxo1LWHAI1Xch0nhIw4bZk4IxlV1UldQicjgwFLgcUOAl4DVV3elv9qKXtE8QBw9Ct26urefSpa4JazkrTS/n7Oxyy54xpgzK3JNaVX8D3gCmAMcAFwHfisgNcculCe3f/3azuj34YLkEh1h6OUP4QfGMMZVfiQFCRAaKyDTgc9zEPr1UdQDQFRjjb/ZS3J49cPfdbvTViy/2/XSxzsS2bZsVIxmTzKJp5vpH4DFVnRWcqKp7RORKf7JlANdLbMMGN39DOcxFEGsv5+bNrWmqMcksmiKme4FvAgsiUlNEWgKo6if+ZMuwebMrVho4EE47rVxOWVLfhWBWlGRM8osmQPwXCG7ietBLM34aP979fH/4YV8OH8skPNZ3wZjUFE2AqKqq+wML3ueoaktFpL+ILBeRLBEZG2abP4nIUhFZIiL/CUofLiIrvdfwaM6XNBYuhGefhauugvbxb1kcrq7hvPNsJjZjTKFoAsTmoClCEZFBwJaSdhKRNOAZYADQARgqIh2KbNMGuB3oo6odgb946Q2Ae4ATgV7APSJSP5oLqvQOHnRzRzdqBP/v/5X5cLG0Snr/fXtSMMYUiqaSehQwWUSeBgRYD/w5iv16AVmquhpARKYAg4DguaWvAp5R1V8BVHWTl34uMENVt3n7zgD6A69Fcd7K7R//gPnzXcV0/bLFxFhHVA10cLOAYIyBKAKEqq4CThKROt7yriiP3QQXTAJycE8EwdoCiMgcIA24V1U/DLNvk6InEJGRwEiA5skwg8yGDXDHHXDOOTBkSJkPV5pWScYYExBVRzkROR+4FrhZRMaJyLg4nb8q0Aboi+up/byIHBHtzqo6UVXTVTW9cePGccpSAo0eDQcOuPqHGJq1hipGAmuVZIwpm2g6yv0TNx7TDbgipsFAiyiOvQFoFrTc1EsLlgNkqOoBVV0DrMAFjGj2TS7vvANvvunGWzruuKh3sxFVjTG+UdWIL+C7Iu91gNlR7FcVWA20wrV6Wgx0LLJNf+AV73MjXLFSQ6ABsAao773WAA0ina9nz55aYW3cqDpggOo//qGam1t8/c6dqs2bq3boEHp9BC1aqLrQcOirRQvVSZNUa9U6NL1WLZdujDGqqkCmhrmvRlPEtM973yMixwIHcOMxlRR48oDrgY+AZcBUVV0iIuODWkV9BGwVkaXAZ8AtqrpVXeX0/cB87zXeS6ucpkyBDz6Aa66Btm3hhRdcUVLAvfe68qDnnot5vCUbUdUY45do5oO4G3gKOAvXbFWB51U1XvUQcVGhR3M9+2zYuBH+/ne45x6YNw9atXLjLHXqBCefDFdc4e7eMYo0J4ONqGqMKUmpR3MVkSrAJ6q6XVXfxNU9tK9owaFC++03+OILuPBCOPdc+OoreO89N3/0FVfASSdBw4bw0EOlOvyECVbhbIzxR8QAoW4WuWeClnNVdYfvuUomH38MeXlwwQVuWcR1WZ4/H95+G844wxU5NWhQ4qFCtVayYiRjjF+i6Sj3iYj8EXhLSyqPMsW9+667+Z900qHpIm4gvoEDQ+9XRLhOb2Cd24wx/oimkvpq3OB8uSLym4jsFJHffM5Xcjh40BUnDRgAVaOJxeGF6/R2551lOqwxxoQVTU/quuWRkaT0zTewZUth8VIZRGqtZIwxfigxQIhIyMkItMgEQiaEd99141qce26ZD9W8eejWSjY8hjHGL9GUe9wS9LkGbhC+BcCZvuQombz7LpxySpkH3QPXKqnoQHvWWskY46cS6yBU9cKgVz+gE/Cr/1mr5Natg+++K1XxkrVWMsZUBKWpOc0Bjo93RpLOe++59xgDhLVWMsZUFNHUQTyF6z0N7omjG/Ctj3lKDu+8A7/7HbRrF9NukVorWXAwxpSnaJ4ggsevyANeU9U5PuUnOezeDZ9+6sZeimHYbrDWSsaYiiOaAPEGsE9VD4KbSlREaqlqmHnJDJ98Arm5pap/sNZKxpiKIpqOcp8ANYOWawIz/clOJbF2rRsqI5x334W6deHUU2M+tI2tZIypKKIJEDU0aJpR73OtCNsnv1Gj4MQT4ckni69TdQHi3HNLHLrbWisZYyqyaIqYdotID1X9FkBEegJ7/c1WBZaXB19+CbVruylC16+Hhx92d3mAhQvd0N4lFC9ZayVjTEUXTYD4C/BfEfkJN+Xo0bgpSFPTokWwa5e7w8+ZA48+Cjk58PLLUL26e3oQceMvRWCtlYwxFV00YzHNF5H2QKC95nJVPRBpnwAR6Q88AaQBL6jqQ0XWjwAeoXC+6adV9QVv3UHgey99napGN+yp32Z5I4z07QtDh7ra47Fj4eefYdo017z1xBPhyCMjHsZaKxljKroS6yBE5Dqgtqr+oKo/AHVE5Noo9kvDzSUxAOgADBWRDiE2fV1Vu3mvF4LS9walV4zgAC5A/O53cOyx7knhtttg0iT3NHHyyZCZGVXrpXCtkqy1kjGmooimkvoqVd0eWFDVX4GrotivF5ClqqtVdT8wBRhUqlxWFPn5rv6haOukYcPcnNM//eSWowgQ1lrJGFPRRRMg0kQKe3t5TwaRm+c4TYD1Qcs5XlpRfxSR70TkDRFpFpReQ0QyReRrEfl9qBOIyEhvm8zNmzdHkaUyWrYMtm6F00IMcHvWWTB3Ljz3HHTpcsgqa61kjKmMoqmk/hB4XUSe85avBj6I0/nfwfXMzhWRq4FXKBwltoWqbhCR1sCnIvK9qq4K3llVJwITAdLT0/2f7S5Q/xAqQAB07OheQay1kjGmsormCeI24FNglPf6nkM7zoWzAQh+ImhKYWU0AKq6VVVzvcUXgJ5B6zZ476uBz4HuUZzTX7Nnu7qHVq2i3sVmgjPGVFbRDPedD8wDsnH1CmcCy6I49nygjYi0EpFqwBAgI3gDETkmaHFg4LgiUl9EqnufGwF9gKVRnNM/qu4J4rTTYhpfyVorGWMqq7BFTCLSFhjqvbYArwOo6hnRHFhV80TkeuAjXDPXF1V1iYiMBzJVNQO4UUQG4gYB3AaM8HY/HnhORPJxQewhVU1sgFizBjZsCF+8FIaNrWSMqawi1UH8CMwGLlDVLAARuSmWg6vq+8D7RdLGBX2+Hbg9xH5zgc6xnMt3s2e79xjHV7KZ4IwxlVWkIqY/ABuBz0TkeRE5C9eTOjXNmgUNGkCHUF05wrPWSsaYykpUIzf+EZHauP4LQ3H1D/8Gpqnqx/5nL3rp6emamZlZ8oal1aaNa6E0fbp/5zDGmHImIgtUNT3UumgqqXer6n9U9UJcS6SFuJZNqWPjRsjKili8FKqvgzHGVGYxzUnt9aIu6HuQMgL1D2EqqEvq62CMMZVRNP0gzKxZbnjv7qG7YlhfB2NMMrIAEY1Zs6B3b6ga+oHL+joYY5KRBYiSbNsGP/wQsf+DjcxqjElGFiBKMmeO60UdoYLaRmY1xiQjCxAlmTXLzS3dq1fYTayvgzEmGcXUiiklzZ7tgkPNyOMT2sisxphkY08QkezaBQsWxDy8hjHGJAMLEJF8/TXk5cU8QJ8xxiQDCxCRzJ7tukb37p3onBhjTLmzABHJrFnQrRscfnhBkg2pYYxJFRYgwvntN9fE9YzC6S8CQ2qsXetavgaG1LAgYYxJRhYgwvn4YzhwAAYOLEiyITWMManE1wAhIv1FZLmIZInI2BDrR4jIZhFZ5L3+N2jdcBFZ6b2G+5nPkDIy3PwPQfUPNqSGMSaV+NYPQkTSgGeAfkAOMF9EMkJMHfq6ql5fZN8GwD1AOqDAAm/fX/3K7yHy8uC99+D88w8Zf8mmDzXGpBI/nyB6AVmqulpV9wNTcBMPReNcYIaqbvOCwgygv0/5LG7uXDcGU1DxEtiQGsaY1OJngGgCrA9azvHSivqjiHwnIm+ISLNY9hWRkSKSKSKZmzdvjle+XfFStWpw7rmHJNuQGsaYVJLoSup3gJaq2gX3lPBKLDur6kRVTVfV9MaNG8cnR6rw9tuu9VLdusVWDxsG2dmQn+/eLTgYY5KVnwFiA9AsaLmpl1ZAVbeqaq63+ALQM9p9fbN8uZtetEjxkjHGpBo/A8R8oI2ItBKRasAQICN4AxE5JmhxILDM+/wRcI6I1BeR+sA5Xpr/MrwsXnhhuZzOGGMqKt9aMalqnohcj7uxpwEvquoSERkPZKpqBnCjiAwE8oBtwAhv320icj8uyACMV9VtfuX1EBkZbmrRZs1K3tYYY5KYqGqi8xAX6enpmpmZWbaDbN4MRx0F48bBvffGJV/GGFORicgCVU0PtS7RldQVy3vvuUpqq38wxhgLEIfIyIAmTVwRkzHGpDgLEAH79sFHH7mnB5FE58YYYxLOAkTAp5+6kfeseMkYYwALEIUyMqBOnUOG9zbGmFRmAQJct+h33nFDa1SvnujcGGNMhWABAuDbb+Gnn6x4yRhjgliAAFe8VKUKnHdeQZJNLWqMSXW+9aSuVDIyoE8faNQIKJxaNDB7XGBqUbDB+YwxqcOeINauhcWLbWpRY4wpwp4gmjaF2bOhdeuCJJta1Bhj7AkC0tLglFPg2GMLksJNIWpTixpjUokFiBBsalFjjLEAEZJNLWqMMVYHEdawYRYQjDGpzZ4gjDHGhORrgBCR/iKyXESyRGRshO3+KCIqIunecksR2Ssii7zXP/3MpzHGmOJ8K2ISkTTgGaAfkAPMF5EMVV1aZLu6wGhgXpFDrFLVbn7lzxhjTGR+PkH0ArJUdbWq7gemAINCbHc/8DCwz8e8GGOMiZGfAaIJsD5oOcdLKyAiPYBmqvpeiP1bichCEflCRE4NdQIRGSkimSKSuXnz5rhl3BhjTAIrqUWkCvB3YEyI1RuB5qraHbgZ+I+IHF50I1WdqKrpqpreuHFjfzNsjDEpxs8AsQFoFrTc1EsLqAt0Aj4XkWzgJCBDRNJVNVdVtwKo6gJgFdDWx7waY4wpws8AMR9oIyKtRKQaMATICKxU1R2q2khVW6pqS+BrYKCqZopIY6+SGxFpDbQBVvuYV2OMMUX41opJVfNE5HrgIyANeFFVl4jIeCBTVTMi7H4aMF5EDgD5wChV3eZXXo0xxhQnqproPMRFenq6ZmZmJjobxhhTqYjIAlVND7XOelIbY4wJyQKEMcaYkCxAGGOMCckChDHGmJAsQBhjjAnJAoQxxpiQLEAYY4wJyQKEMcaYkCxAGGOMCckChDHGmJAsQBhjjAnJAoQxxpiQLEAYY4wJyQKEMcaYkCxAGGOMCckChDHGmJB8DRAi0l9ElotIloiMjbDdH0VERSQ9KO12b7/lInKun/k0xhhTnG9TjnpzSj8D9ANygPkikqGqS4tsVxcYDcwLSuuAm8O6I3AsMFNE2qrqQb/ya4wx5lB+PkH0ArJUdbWq7gemAINCbHc/8DCwLyhtEDBFVXNVdQ2Q5R3PGGNMOfEzQDQB1gct53hpBUSkB9BMVd+LdV9v/5EikikimZs3b45Pro0xxgAJrKQWkSrA34ExpT2Gqk5U1XRVTW/cuHH8MmeMMca/OghgA9AsaLmplxZQF+gEfC4iAEcDGSIyMIp9jTHG+MzPJ4j5QBsRaSUi1XCVzhmBlaq6Q1UbqWpLVW0JfA0MVNVMb7shIlJdRFoBbYBvfMyrMcaYInx7glDVPBG5HvgISANeVNUlIjIeyFTVjAj7LhGRqcBSIA+4zlowGWNM+fK1DkJV31fVtqp6nKpO8NLGhQoOqtrXe3oILE/w9munqh/4lcfJk6FlS6hSxb1PnuzXmYwxpnLxsw6iwps8GUaOhD173PLatW4ZYNiwxOXLGGMqgpQeauPOOwuDQ8CePS7dGGNSXUoHiHXrYks3xphUktIBonnz2NKNMSaVpHSAmDABatU6NK1WLZdujDGpLqUDxLBhMHEitGgBIu594kSroDbGGEjxVkzggoEFBGOMKS6lnyCMMcaEZwHCGGNMSBYgjDHGhGQBwhhjTEgWIIwxxoQkqproPMSFiGwG1pbhEI2ALXHKTmVi151a7LpTSzTX3UJVQ864ljQBoqxEJFNV0xOdj/Jm151a7LpTS1mv24qYjDHGhGQBwhhjTEgWIApNTHQGEsSuO7XYdaeWMl231UEYY4wJyZ4gjDHGhGQBwhhjTEgpHyBEpL+ILBeRLBEZm+j8+ElEXhSRTSLyQ1BaAxGZISIrvff6icxjvIlIMxH5TESWisgSERntpSf7ddcQkW9EZLF33fd56a1EZJ73fX9dRKolOq9+EJE0EVkoIu96y6ly3dki8r2ILBKRTC+t1N/1lA4QIpIGPAMMADoAQ0WkQ2Jz5auXgf5F0sYCn6hqG+ATbzmZ5AFjVLUDcBJwnfc3TvbrzgXOVNWuQDegv4icBDwMPKaqvwN+Ba5MXBZ9NRpYFrScKtcNcIaqdgvq/1Dq73pKBwigF5ClqqtVdT8wBRiU4Dz5RlVnAduKJA8CXvE+vwL8vjzz5DdV3aiq33qfd+JuGk1I/utWVd3lLR7mvRQ4E3jDS0+66wYQkabA+cAL3rKQAtcdQam/66keIJoA64OWc7y0VHKUqm70Pv8MHJXIzPhJRFoC3YF5pMB1e8Usi4BNwAxgFbBdVfO8TZL1+/44cCuQ7y03JDWuG9yPgI9FZIGIjPTSSv1dT/kZ5UwhVVURScp2zyJSB3gT+Iuq/uZ+VDrJet2qehDoJiJHANOA9onNkf9E5AJgk6ouEJG+Cc5OIpyiqhtE5Ehghoj8GLwy1u96qj9BbACaBS039dJSyS8icgyA974pwfmJOxE5DBccJqvqW15y0l93gKpuBz4DTgaOEJHAD8Nk/L73AQaKSDauyPhM4AmS/7oBUNUN3vsm3I+CXpThu57qAWI+0MZr4VANGAJkJDhP5S0DGO59Hg68ncC8xJ1X/vwvYJmq/j1oVbJfd2PvyQERqQn0w9W/fAZc7G2WdNetqreralNVbYn7//ypqg4jya8bQERqi0jdwGfgHOAHyvBdT/me1CJyHq7MMg14UVUnJDZH/hGR14C+uCGAfwHuAaYDU4HmuOHS/6SqRSuyKy0ROQWYDXxPYZn0Hbh6iGS+7i64Csk03A/Bqao6XkRa435ZNwAWAv+jqrmJy6l/vCKmv6rqBalw3d41TvMWqwL/UdUJItKQUn7XUz5AGGOMCS3Vi5iMMcaEYQHCGGNMSBYgjDHGhGQBwhhjTEgWIIwxxoRkAcKYEojIQW90zMArbgP7iUjL4NF1jalIbKgNY0q2V1W7JToTxpQ3e4IwppS8sff/5o2//42I/M5Lbykin4rIdyLyiYg099KPEpFp3hwNi0Wkt3eoNBF53pu34WOv5zMicqM3j8V3IjIlQZdpUpgFCGNKVrNIEdMlQet2qGpn4Glcj3yAp4BXVLULMBl40kt/EvjCm6OhB7DES28DPKOqHYHtwB+99LFAd+84o/y5NGPCs57UxpRARHapap0Q6dm4SXlWewMC/qyqDUVkC3CMqh7w0jeqaiMR2Qw0DR7iwRuCfIY3mQsichtwmKo+ICIfArtww6FMD5rfwZhyYU8QxpSNhvkci+AxgQ5SWDd4Pm7Gwx7A/KDRSI0pFxYgjCmbS4Lev/I+z8WNJAowDDdYILjpHq+Bgsl86oU7qIhUAZqp6mfAbUA9oNhTjDF+sl8kxpSspjczW8CHqhpo6lpfRL7DPQUM9dJuAF4SkVuAzcDlXvpoYKKIXIl7UrgG2EhoacAkL4gI8KQ3r4Mx5cbqIIwpJa8OIl1VtyQ6L8b4wYqYjDHGhGRPEMYYY0KyJwhjjDEhWYAwxhgTkgUIY4wxIVmAMMYYE5IFCGOMMSH9fyzQYCuU3spXAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#BATCH NORMALIZATION AND DATA AUGMENTATION\n",
        "\n",
        "model4 = models.Sequential()\n",
        "#1 conv, BN, relu, max pool\n",
        "model4.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3)))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(Activation('relu'))\n",
        "model4.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "#2 conv, BN, relu, max pool\n",
        "model4.add(Conv2D(64, (4, 4)))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(Activation('relu'))\n",
        "model4.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model4.add(Flatten())\n",
        "\n",
        "\n",
        "#Dense layers\n",
        "model4.add(Dense(256))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(Activation('relu'))\n",
        "model4.add(Dense(10))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "#Data Augmentation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, zoom_range = 0.2, shear_range = 0.2, horizontal_flip=True)\n",
        "train_datagen.fit(x_train)\n",
        "train_generator = train_datagen.flow(x_train, y_train_vec, batch_size=100)\n",
        "\n",
        "#Optimizer\n",
        "model4.compile(optimizer=optimizers.RMSprop(learning_rate=0.0001), loss = 'categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "\n",
        "#Train\n",
        "history = model4.fit(train_generator, steps_per_epoch=len(x_train)/100, epochs=50, validation_data=(x_val, y_val))\n",
        "\n",
        "# Evaluate your model performance (testing accuracy) on testing data.\n",
        "loss_and_acc = model4.evaluate(x_test, y_test_vec)\n",
        "print(\"loss = \" + str(loss_and_acc[0]))\n",
        "print(\"accuracy = \" + str(loss_and_acc[1]))\n",
        "\n",
        "\n",
        "# Plot the loss curve\n",
        "%matplotlib inline\n",
        "\n",
        "epochs = range(50)\n",
        "train_acc = history.history['acc']\n",
        "valid_acc = history.history['val_acc']\n",
        "plt.plot(epochs, train_acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, valid_acc, 'r', label='Validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "HtfzUvo8wBax"
      },
      "outputs": [],
      "source": [
        "# First model accuracy: 0.647\n",
        "# Model with Batch Normalization: 0.712\n",
        "# Model with Batch Normalization and Data Augmentation: 0.749"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}